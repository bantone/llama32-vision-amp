{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f918592a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import requests\n",
    "import base64\n",
    "import mimetypes\n",
    "import hashlib\n",
    "import uuid\n",
    "import json\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Image\n",
    "\n",
    "# Fetch NVIDIA API settings from environment variables\n",
    "NVIDIA_APIKEY = os.getenv(\"NVIDIA_APIKEY\")\n",
    "NVIDIA_ENDPOINT = os.getenv(\"NVIDIA_ENDPOINT\")\n",
    "\n",
    "if not NVIDIA_APIKEY:\n",
    "    raise ValueError(\"NVIDIA_APIKEY environment variable is not set!\")\n",
    "if not NVIDIA_ENDPOINT:\n",
    "    raise ValueError(\"NVIDIA_ENDPOINT environment variable is not set!\")\n",
    "\n",
    "# Define the Llama-3.2 API endpoints dynamically\n",
    "llm_options = {\n",
    "    \"Llama-3.2-11b\": {\n",
    "        \"invoke_url\": f\"https://ai.api.nvidia.com/v1/gr/meta/llama-3.2-11b-vision-instruct/chat/completions\",\n",
    "        \"model\": \"meta/llama-3.2-11b-vision-instruct\"\n",
    "    },\n",
    "    \"Llama-3.2-90b\": {\n",
    "        \"invoke_url\": f\"https://ai.api.nvidia.com/v1/gr/meta/llama-3.2-90b-vision-instruct/chat/completions\",\n",
    "        \"model\": \"meta/llama-3.2-90b-vision-instruct\"\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f03ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_hash(file_data):\n",
    "    return hashlib.md5(file_data).hexdigest()\n",
    "\n",
    "# File Uploader\n",
    "file_uploader = widgets.FileUpload(accept='image/*', multiple=False)\n",
    "display(file_uploader)\n",
    "\n",
    "uploaded_images = {}\n",
    "selected_image = None\n",
    "\n",
    "def on_upload(change):\n",
    "    global selected_image\n",
    "    if file_uploader.value:\n",
    "        for file_name, file_info in file_uploader.value.items():\n",
    "            file_data = file_info['content']\n",
    "            file_hash = compute_hash(file_data)\n",
    "            \n",
    "            if file_hash not in uploaded_images:\n",
    "                unique_id = str(uuid.uuid4())\n",
    "                mime_type = mimetypes.guess_type(file_name)[0]\n",
    "                image_data = {\n",
    "                    \"id\": unique_id,\n",
    "                    \"name\": file_name,\n",
    "                    \"mime_type\": mime_type,\n",
    "                    \"data\": base64.b64encode(file_data).decode(),\n",
    "                }\n",
    "                uploaded_images[file_hash] = image_data\n",
    "                selected_image = image_data\n",
    "                display(Image(data=file_data))\n",
    "            else:\n",
    "                print(\"This image has already been uploaded.\")\n",
    "\n",
    "file_uploader.observe(on_upload, names='value')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a265afb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prompt for questions\n",
    "prompt = widgets.Text(placeholder=\"Ask a question about the image:\")\n",
    "display(prompt)\n",
    "\n",
    "output = widgets.Output()\n",
    "display(output)\n",
    "\n",
    "def on_submit(change):\n",
    "    if selected_image and prompt.value:\n",
    "        model = llm_options[\"Llama-3.2-11b\"][\"model\"]\n",
    "        invoke_url = llm_options[\"Llama-3.2-11b\"][\"invoke_url\"]\n",
    "        payload = {\n",
    "            \"model\": model,\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f'{prompt.value} <img src=\"data:{selected_image[\"mime_type\"]};base64,{selected_image[\"data\"]}\" />',\n",
    "                }\n",
    "            ],\n",
    "            \"max_tokens\": 1024,\n",
    "            \"temperature\": 1.0,\n",
    "            \"top_p\": 1.0,\n",
    "            \"stream\": False,\n",
    "        }\n",
    "        \n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {NVIDIA_APIKEY}\",\n",
    "            \"Accept\": \"application/json\",\n",
    "            \"Content-Type\": \"application/json\",\n",
    "        }\n",
    "        \n",
    "        with output:\n",
    "            output.clear_output()\n",
    "            print(\"Processing your question...\")\n",
    "            try:\n",
    "                response = requests.post(invoke_url, headers=headers, json=payload)\n",
    "                if response.status_code == 200:\n",
    "                    result = response.json()\n",
    "                    print(\"AI Response:\")\n",
    "                    print(json.dumps(result, indent=4))\n",
    "                else:\n",
    "                    print(f\"Error: {response.status_code}\")\n",
    "                    print(response.text)\n",
    "            except Exception as e:\n",
    "                print(f\"Error during API request: {e}\")\n",
    "\n",
    "prompt.observe(on_submit, names='value')\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
